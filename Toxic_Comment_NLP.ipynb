{"cells":[{"metadata":{},"cell_type":"markdown","source":"# About this Notebook\n\nThe goal of this notebook is to build a classifier to find toxic comments. The data has been taken from a series of Kaggle competitions to classify Wikipedia comments as toxic/nontoxic. The data has been sourced from Google and Jigsaw. \n\nThe notebook will start with simple bag-of-words and tf-idf features and use simple models like logistic regression and Naive Bayes to perform classification with these features. Though the full dataset includes non-English comments, I will restrict myself to English-only comment for this iteration. \n\nWe will then move on to deep learning approaches, using a combination of pretrained word embeddings and simple deep learning models like RNNs and 1D convolutions to do more benchmarking. \n\nNext, we will explore deep learning models that have 'memory' using LSTMs (Long Short Term Memory) and GRUs (Gated Recurrent Units). \n\nFinally, we will approach state of the art performance using pretrained models like BERT and xlnet.\n\nFor metrics, I will focus on both ROC and precision-recall curves. In addition, I will look at the confusion matrix and performance across different flavors of toxicity.\n\nCredits:\n- https://www.kaggle.com/tanulsingh077/deep-learning-for-nlp-zero-to-transformers-bert\n- https://www.kaggle.com/jagangupta/stop-the-s-toxic-comments-eda\n- https://www.kaggle.com/clinma/eda-toxic-comment-classification-challenge\n- https://www.kaggle.com/abhi111/naive-bayes-baseline-and-logistic-regression","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"I will do a tiered approach to feature engineering and building the model:\n\nNo Deep Learning:\n1. Do cleanup of text for things like punctuation, numbers, weird symbols, etc. \n2. Use regex and string functions to essentially do tokenization.\n3. Create non-semantic features related to capitalization, misspelling, punctuation, length, repetition, etc. \n4. Use NB and logistic models with regularization.\n5. Have clear metrics that evaluate on different types of toxicity and pull out examples where model does poorly.\n\nDeep Learning:\n1. Use standard tokenizers and compare with 'homegrown' version from above.\n2. Use open source word embeddings for corpus as input to RNN models. Quantify how misspellings affect the standard tokenizers.\n3. Find way to input additional features like punctuation/capitalization from approach above to Deep Learning RNN models.\n4. Try progressively more complicated deep learning sequence models approaching SOTA.\n5. Use metrics from above.\n\nPotential Modules:\n1. Correct misspellings\n2. Analytics for preprocessing\n3. Analytics for model performance (use multi-labels, make easy way to look at specific examples)\n4. Automatically generate a lookup table for common variations of words (particularly toxic words, e.g., 'mothafucka' -> 'motherfucker')\n\n\n","execution_count":null},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nfrom collections import defaultdict as ddict, Counter\nfrom itertools import compress\nfrom tqdm import tqdm\nfrom scipy.sparse import csr_matrix, hstack\nfrom sklearn import metrics\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\nfrom wordcloud import WordCloud\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom plotly import graph_objs as go\nimport plotly.express as px\nimport plotly.figure_factory as ff\nimport re\n\nimport random\nimport string\nfrom nltk.corpus import stopwords\nstop = stopwords.words('english')\nfrom nltk.stem.wordnet import WordNetLemmatizer \nlemmatizer = WordNetLemmatizer()\nfrom nltk.tokenize import word_tokenize\n# Tweet tokenizer does not split at apostophes which is what we want\nfrom nltk.tokenize import TweetTokenizer   \npd.options.display.max_rows = 999","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pre_path = '/kaggle/input/'","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train = pd.read_csv(pre_path + 'jigsaw-multilingual-toxic-comment-classification/jigsaw-toxic-comment-train.csv')\n#The following is a non-English dataset and won't be used presently\nvalidation = pd.read_csv(pre_path + 'jigsaw-multilingual-toxic-comment-classification/validation.csv')\n#The following is a non-English dataset and won't be used presently\ntest = pd.read_csv(pre_path + 'jigsaw-multilingual-toxic-comment-classification/test.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## EDA","execution_count":null},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"print(train.info())\ntrain.head()\nprint(train.describe())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"CATEGORIES = list(train.columns[2:8])\ndf_comb = train.groupby(CATEGORIES)\\\n                    .size()\\\n                    .sort_values(ascending=False)\\\n                    .reset_index()\\\n                    .rename(columns={0: 'count'})\n\ndf_comb['label'] ='nontoxic'\n\nfor i in range(len(df_comb)):\n    label_index = df_comb.iloc[i,0:6].values.astype(bool)\n    label = ', '.join(list(compress(CATEGORIES, label_index)))\n    if label:\n        df_comb.loc[i, 'label'] = label\n\ndf_comb.head(n=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_comb[(df_comb['count']>20) & (df_comb['count']<100000)].plot.bar(x='label', y='count', figsize=(17,8))\nplt.yscale('log')\nplt.xticks(size=15)\n\n#Think of a more compelling multilabel visualization (decision tree/dendogram with labels?)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(train.iloc[:,2:8].corr(), annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"By looking at the labels, we can see that roughly 90% of the 200K+ comments are nontoxic. The remaining unsavory comments have a combination of labels including toxic, severe_toxic, obscene, insult, identity_hate, and threat. The bulk of the comments are vanilla toxic and the next most common are comments that are both toxic with a combination of obscence and/or insult. Interestingly, about 4% of the 22.5K unsavory comments do not have a toxic label; they are a combination of obscene and insult. Overall, toxic is the label to predict, though it will be interesting to see how different types of models do with different flavors of toxicity.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Preprocessing steps","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#s=\"string. With. Punctuation?\" \n#s.translate(str.maketrans('', '', string.punctuation))\n#set(string.punctuation)\n\nlemmatizer.lemmatize('rocks')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#First let's try simple regex and string-based options. \n#Later I can use more nltk and/or word embedding based models\n#Additional cleaning steps should include lemmatization and trying to correct for misspellings (n-gram approach?)\n\n\ndef remove_punctuation(text, exclude=[\"'\"]):\n    #Remove punctuation but leave apostrophe\n    #TO DO: remove numbers\n    if exclude:\n        punctuation_to_remove = ''.join(list(set(string.punctuation)-set(exclude)))\n    else:\n        punctuation_to_remove = string.punctuation\n    text = text.translate(str.maketrans('', '', punctuation_to_remove)\n    return text\n                          \ndef remove_numbers(text):\n    #Remove punctuation but leave apostrophe\n    #TO DO: remove numbers\n    text = text.translate(str.maketrans('', '', string.digits)\n    return text\n                          \ndef keep_alpha_char(text):\n    pass\n\ndef remove_stop_words(text):\n    return ' '.join([word.strip() for word in text.split() if word not in stop])\n\ndef tokenize(text):\n    return text.lower().split()\n\ndef clean_text(text):\n    return remove_stop_words(remove_punctuation(text))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def lemmatize(text_list, lemmatizer=None):\n    if lemmatizer:\n        return [lemmatizer.lemmatize(word) for word in text_list]\n    else:\n        return text_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"word_counter = {}\n\nfor categ in CATEGORIES:\n    d = Counter()\n    train[train[categ] == 1]['comment_text'].apply(lambda t: d.update(lemmatize(clean_text(t).split())))\n    word_counter[categ] = pd.DataFrame.from_dict(d, orient='index')\\\n                                        .rename(columns={0: 'count'})\\\n                                        .sort_values('count', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def angry_color_func(word, font_size, position, orientation, random_state=None,\n                    **kwargs):\n    return \"hsl(%d, 100%%, 50%%)\" % ((random.randint(-40, 40)+360)%360)\n\nfor w in word_counter:\n    wc = word_counter[w]\n\n    wordcloud = WordCloud(\n          background_color='black',\n          max_words=200,\n          max_font_size=100, \n          random_state=461\n         ).generate_from_frequencies(wc.to_dict()['count'])\n\n    fig = plt.figure(figsize=(8, 8))\n    plt.title(w.upper().replace('_', ' '), size=40)\n    plt.imshow(wordcloud.recolor(color_func=angry_color_func, random_state=3),\n           interpolation=\"bilinear\")\n    plt.axis('off')\n\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Overall, we can see a lot of disturbing words for the word clouds in each category. Identity Hate has more specific attacks against race, religion, sexual orientation, and gender. Threat has more hate-related verbs and seems to be a bit different in its words from all the other categories. The most represented categories in the dataset are toxic/obscene/insult. Overall, these categories seem to have similar highly represented words. We will now see if these common words translate into highly predictive features. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Quantify how much misspellings and long tail might be affecting results\nword_counter['threat'].hist(bins=60)\nplt.yscale('log')\nprint(sum(word_counter['threat']['count']==1))\nprint(len(word_counter['threat']))\nthreat = word_counter['threat']\nthreat.tail(n=999)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will drop the other columns and approach this problem as a Binary Classification Problem and also we will have our exercise done on a smaller subsection of the dataset(only 12000 data points) to make it easier to train the models","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Sample data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train.drop(['severe_toxic','obscene','threat','insult','identity_hate'],axis=1,inplace=True)\n\ntrain_full = train.copy()\n#train = train.loc[:10000,:]\ntrain.comment_text[train.toxic==1][1:2].values\ntrain.toxic.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create train and test sets","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"xtrain, xvalid, ytrain, yvalid = train_test_split(train.comment_text.values, train.toxic.values, \n                                                  stratify=train.toxic.values, \n                                                  random_state=42, \n                                                  test_size=0.2, shuffle=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtrain","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create Features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"count_vectorizer = CountVectorizer(stop_words='english')\ncount_train = count_vectorizer.fit_transform(xtrain)\ncount_valid = count_vectorizer.transform(xvalid)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(count_valid)\ncount_vectorizer.get_feature_names()[200000:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Define Metrics","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def run_metrics(predictions, predictions_prob, target, visualize=True):\n    fpr, tpr, thresholds = metrics.roc_curve(target, predictions_prob)\n    roc_auc = metrics.auc(fpr, tpr)\n    precision, recall, thresholds = metrics.precision_recall_curve(target, predictions_prob)\n    average_precision = metrics.average_precision_score(yvalid, pred)\n    #average_recall = metrics.recall_score(yvalid, pred)\n    print('Average precision-recall score: {0:0.2f}'.format(\n      average_precision))\n    accuracy = metrics.accuracy_score(yvalid, pred)\n    print(metrics.confusion_matrix(yvalid, pred, labels=[0,1]))\n    print(\"Accuracy Score: {0:0.2f}\".format(accuracy))\n    if visualize:\n        plt.figure()\n        plt.plot(fpr, tpr)\n        plt.title('ROC curve, AUC: {0:0.2f}'.format(roc_auc))\n        plt.xlabel('False Positive Rate')\n        plt.ylabel('True Positive Rate')\n        \n        plt.show()\n        \n        plt.figure()\n        plt.plot(recall, precision)\n        plt.title('Precision-Recall curve')\n        plt.xlabel('Recall')\n        plt.ylabel('Precision')\n        plt.show()\n        #disp = metrics.plot_precision_recall_curve(nb_classifier, count_valid, yvalid)\n        #disp.ax_.set_title('2-class Precision-Recall curve: '\n                   #'AP={0:0.2f}'.format(average_precision))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train Naive Bayes Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"nb_classifier = MultinomialNB()\n\nnb_classifier.fit(count_train, ytrain)\npred = nb_classifier.predict(count_valid)\npred_proba = nb_classifier.predict_proba(count_valid)[:,1]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"run_metrics(pred, pred_proba, yvalid, visualize=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Use Tfidf for the features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)\ncount_train_idf = tfidf_vectorizer.fit_transform(xtrain)\ncount_valid_idf = tfidf_vectorizer.transform(xvalid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidf_vectorizer.get_feature_names()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"nb_classifier.fit(count_train_idf, ytrain)\npred = nb_classifier.predict(count_valid_idf)\npred_proba = nb_classifier.predict_proba(count_valid_idf)[:,1]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"run_metrics(pred, pred_proba, yvalid, visualize=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Use Deep Learning","execution_count":null},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom keras.models import Sequential\nfrom keras.layers.recurrent import LSTM, GRU,SimpleRNN\nfrom keras.layers.core import Dense, Activation, Dropout\nfrom keras.layers.embeddings import Embedding\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.utils import np_utils\nfrom sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\nfrom keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\nfrom keras.preprocessing import sequence, text\nfrom keras.callbacks import EarlyStopping, History, ModelCheckpoint, TensorBoard\nfrom tensorflow.keras.optimizers import Adam\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preprocess data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### We will check the maximum number of words that can be present in a comment , this will help us in padding later","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"max_len = int(round(train['comment_text'].apply(lambda x:len(str(x).split())).max(), -2)+100)\nprint(\"Max length of comment text is: {}\".format(max_len))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### First do Tokenization of input corpus","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# using keras tokenizer here\ntoken = text.Tokenizer(num_words=None)\ntoken_toxic = text.Tokenizer(num_words=None)\ntoken_nontoxic = text.Tokenizer(num_words=None)\n\ntoken.fit_on_texts(list(xtrain) + list(xvalid))\ntoken_toxic.fit_on_texts(train.comment_text.values[train.toxic==1])\ntoken_nontoxic.fit_on_texts(train.comment_text.values[train.toxic==0])\n\nxtrain_seq = token.texts_to_sequences(xtrain)\nxvalid_seq = token.texts_to_sequences(xvalid)\n\n#zero pad the sequences\nxtrain_pad = sequence.pad_sequences(xtrain_seq, maxlen=max_len)\nxvalid_pad = sequence.pad_sequences(xvalid_seq, maxlen=max_len)\n\nword_index = token.word_index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"word_toxic = token_toxic.word_index\nword_nontoxic = token_nontoxic.word_index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(word_toxic))\nprint(len(word_nontoxic))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Example for fitting tokenizer line-by-line if corpus is too big to fit into memory\n\nwith open('/Users/liling.tan/test.txt') as fin: for line in fin:\nt.fit_on_texts(line.split()) # Fitting the tokenizer line-by-line.\n\nM = []\n\nwith open('/Users/liling.tan/test.txt') as fin: for line in fin:\n\n    # Converting the lines into matrix, line-by-line.\n    m = t.texts_to_matrix([line], mode='count')[0]\n    M.append(m)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Use pretrained word embeddings","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Convert our one-hot word index into semantic rich GloVe vectors","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# load the GloVe vectors in a dictionary:\n\nembeddings_index = {}\nf = open(pre_path + 'glove840b300dtxt/glove.840B.300d.txt','r',encoding='utf-8')\nfor line in tqdm(f):\n    values = line.split(' ')\n    word = values[0]\n    coefs = np.asarray([float(val) for val in values[1:]])\n    embeddings_index[word] = coefs\nf.close()\n\nprint('Found %s word vectors.' % len(embeddings_index))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nwords_not_in_corpus = ddict(int)\nwords_in_corpus = ddict(int)\n# create an embedding matrix for the words we have in the dataset\nembedding_matrix = np.zeros((len(word_index) + 1, 300))\nfor word, i in tqdm(word_nontoxic.items()):\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None:\n        embedding_matrix[i] = embedding_vector\n        words_in_corpus[word]+=1\n    else:\n        words_not_in_corpus[word]+=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(words_not_in_corpus))\nprint(len(words_in_corpus))\nmax(words_not_in_corpus.values())\nmax(words_in_corpus.values())\n\n#For the full dataset, more than half the 'words' are not found in the glove embeddings\n#For the 10K sample dataset, only ~25% of the words are not found in the glove embeddings\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(words_not_in_corpus))\nprint(len(words_in_corpus))\nmax(words_not_in_corpus.values())\nmax(words_in_corpus.values())\n\n#For the full dataset, more than half the 'words' are not found in the glove embeddings\n#For the 10K sample dataset, only ~25% of the words are not found in the glove embeddings\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Save embeddings so they can be easily loaded\nnp.save('/kaggle/working/glove_embedding_for_full_data', embedding_matrix)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Load embeddings\nembedding_matrix = np.load('/kaggle/working/glove_embedding_for_10K_sample.npy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embedding_matrix.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Simple RNN Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"opt = Adam(learning_rate=0.0001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model1 = Sequential()\nmodel1.add(Embedding(len(word_index) + 1,\n                 300,\n                 input_length=max_len))\nmodel1.add(SimpleRNN(100))\nmodel1.add(Dense(1, activation='relu'))\nmodel1.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n    \nmodel1.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint,TensorBoard, EarlyStopping\nEPOCHS = 10\ncheckpoint_filepath = '/kaggle/working/'\nmodel_checkpoint_callback = ModelCheckpoint(\n    filepath=checkpoint_filepath,\n    save_weights_only=True,\n    monitor='val_acc',\n    mode='max',\n    save_best_only=True)\n\n\nmy_callbacks = [\n    model_checkpoint_callback,\n    TensorBoard(log_dir='/kaggle/working/logs'),\n    EarlyStopping(monitor='val_loss', patience=3)\n]\nmodel_checkpoint_callback","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model1.fit(xtrain_pad, \n           ytrain, \n           epochs=50, \n           batch_size=100, \n           callbacks=my_callbacks,\n           validation_split=0.2,)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = model1.predict(xvalid_pad)[:, 0]\npreds = scores>.5\nrun_metrics(preds, scores, yvalid)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Simple LSTM Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# A simple LSTM with glove embeddings and one dense layer\nmodel = Sequential()\nmodel.add(Embedding(len(word_index) + 1,\n                 300,\n                 weights=[embedding_matrix],\n                 input_length=max_len,\n                 trainable=False))\n\nmodel.add(LSTM(100, dropout=0.3, recurrent_dropout=0.3))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n    \nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(xtrain_pad, \n          ytrain, \n          epochs=50, \n          batch_size=100,\n          callbacks=my_callbacks,\n          validation_split=0.2,)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = model.predict(xvalid_pad)\npreds = scores>.5\nrun_metrics(preds, scores, yvalid)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Summary","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"So far, with very little preprocessing, we have achieved high accuracy. This is a little bit misleading however because the training set is highly imbalanced (roughly 10% positive/toxic class). \n\nSlightly older techniques, bag-of-words and tf-idf have done better than a simple deep learning models out-of-the-box. This can been seen by the higher AUCs and accuracy of these models in contrast to the simple RNN model. In addition, training these models was extremely fast, even on a local machine. In contrast, the deep learning models required more than 10 minutes to train even five epochs. In addition, trainingg the simple RNN required playing around with the learning rate to get network to learn. The first few attempts produced labels of all zeros. \n\nThe simple LSTM model starts to improve dramatically over the simple RNN model even with only 5 epochs, showing that using the semantic rich word embeddings and including memory already improve simple deep learning results. Though the overall accuracy has decreased in the LSTM model vs the Naive Bayes models, the AUC and precision-recall and ROC curves are much better than the simple models. As we approach more state-of-the-art (SOTA) models and move beyond simple proof-of-concept model training, i.e., try different network parameters, experiment with data preprocessing, do hyperparameter optimization, train until the results start to degrade, add regularization, etc., the results will likely improve even more dramatically.\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Try a GRU Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# GRU with glove embeddings and two dense layers\n model = Sequential()\n model.add(Embedding(len(word_index) + 1,\n                 300,\n                 weights=[embedding_matrix],\n                 input_length=max_len,\n                 trainable=False))\n model.add(SpatialDropout1D(0.3))\n model.add(GRU(300))\n model.add(Dense(1, activation='sigmoid'))\n\n model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])   \n    \nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"markdown","source":"%%time\n# GRU with glove embeddings and two dense layers\n model = Sequential()\n model.add(Embedding(len(word_index) + 1,\n                 300,\n                 weights=[embedding_matrix],\n                 input_length=max_len,\n                 trainable=False))\n model.add(SpatialDropout1D(0.3))\n model.add(GRU(300))\n model.add(Dense(1, activation='sigmoid'))\n\n model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])   \n    \nmodel.summary()","execution_count":null},{"metadata":{"trusted":false},"cell_type":"markdown","source":"model.fit(xtrain_pad, ytrain, nb_epoch=5, batch_size=64)","execution_count":null},{"metadata":{"trusted":false},"cell_type":"markdown","source":"scores = model.predict(xvalid_pad)\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Bidirectional RNN Model","execution_count":null},{"metadata":{"trusted":false},"cell_type":"markdown","source":"%%time\n# A simple bidirectional LSTM with glove embeddings and one dense layer\nmodel = Sequential()\nmodel.add(Embedding(len(word_index) + 1,\n                 300,\n                 weights=[embedding_matrix],\n                 input_length=max_len,\n                 trainable=False))\nmodel.add(Bidirectional(LSTM(300, dropout=0.3, recurrent_dropout=0.3)))\n\nmodel.add(Dense(1,activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n    \n    \nmodel.summary()","execution_count":null},{"metadata":{"trusted":false},"cell_type":"markdown","source":"model.fit(xtrain_pad, ytrain, nb_epoch=5, batch_size=64)","execution_count":null},{"metadata":{"trusted":false},"cell_type":"markdown","source":"scores = model.predict(xvalid_pad)\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Seq2seq Architecture","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#TBD\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Transformers/Attention/BERT","execution_count":null},{"metadata":{"trusted":false},"cell_type":"markdown","source":"# Loading Dependencies\nimport os\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Dense, Input\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom kaggle_datasets import KaggleDatasets\nimport transformers\n\nfrom tokenizers import BertWordPieceTokenizer","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Encoder FOr DATA for understanding waht encode batch does read documentation of hugging face tokenizer :\nhttps://huggingface.co/transformers/main_classes/tokenizer.html here","execution_count":null},{"metadata":{"trusted":false},"cell_type":"markdown","source":"def fast_encode(texts, tokenizer, chunk_size=256, maxlen=512):\n    \"\"\"\n    Encoder for encoding the text into sequence of integers for BERT Input\n    \"\"\"\n    tokenizer.enable_truncation(max_length=maxlen)\n    tokenizer.enable_padding(max_length=maxlen)\n    all_ids = []\n    \n    for i in tqdm(range(0, len(texts), chunk_size)):\n        text_chunk = texts[i:i+chunk_size].tolist()\n        encs = tokenizer.encode_batch(text_chunk)\n        all_ids.extend([enc.ids for enc in encs])\n    \n    return np.array(all_ids)","execution_count":null},{"metadata":{"trusted":false},"cell_type":"markdown","source":"#IMP DATA FOR CONFIG\n\nAUTO = tf.data.experimental.AUTOTUNE\n\n\n# Configuration\nEPOCHS = 3\nBATCH_SIZE = 16 \nMAX_LEN = 192","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Tokenization\n\nFor understanding please refer to hugging face documentation again","execution_count":null},{"metadata":{"trusted":false},"cell_type":"markdown","source":"# First load the real tokenizer\ntokenizer = transformers.DistilBertTokenizer.from_pretrained('distilbert-base-multilingual-cased')\n# Save the loaded tokenizer locally\ntokenizer.save_pretrained('.')\n# Reload it with the huggingface tokenizers library\nfast_tokenizer = BertWordPieceTokenizer('vocab.txt', lowercase=False)\nfast_tokenizer","execution_count":null},{"metadata":{"trusted":false},"cell_type":"markdown","source":"x_train = fast_encode(train1.comment_text.astype(str), fast_tokenizer, maxlen=MAX_LEN)\nx_valid = fast_encode(valid.comment_text.astype(str), fast_tokenizer, maxlen=MAX_LEN)\nx_test = fast_encode(test.content.astype(str), fast_tokenizer, maxlen=MAX_LEN)\n\ny_train = train1.toxic.values\ny_valid = valid.toxic.values","execution_count":null},{"metadata":{"trusted":false},"cell_type":"markdown","source":"train_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((x_train, y_train))\n    .repeat()\n    .shuffle(2048)\n    .batch(BATCH_SIZE)\n    .prefetch(AUTO)\n)\n\nvalid_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((x_valid, y_valid))\n    .batch(BATCH_SIZE)\n    .cache()\n    .prefetch(AUTO)\n)\n\ntest_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices(x_test)\n    .batch(BATCH_SIZE)\n)","execution_count":null},{"metadata":{"trusted":false},"cell_type":"markdown","source":"def build_model(transformer, max_len=512):\n    \"\"\"\n    function for training the BERT model\n    \"\"\"\n    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n    sequence_output = transformer(input_word_ids)[0]\n    cls_token = sequence_output[:, 0, :]\n    out = Dense(1, activation='sigmoid')(cls_token)\n    \n    model = Model(inputs=input_word_ids, outputs=out)\n    model.compile(Adam(lr=1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n    \n    return model","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Starting Training\n\nIf you want to use any another model just replace the model name in transformers._____ and use accordingly","execution_count":null},{"metadata":{"trusted":false},"cell_type":"markdown","source":"%%time\nwith strategy.scope():\n    transformer_layer = (\n        transformers.TFDistilBertModel\n        .from_pretrained('distilbert-base-multilingual-cased')\n    )\n    model = build_model(transformer_layer, max_len=MAX_LEN)\nmodel.summary()","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"n_steps = x_train.shape[0] // BATCH_SIZE\ntrain_history = model.fit(\n    train_dataset,\n    steps_per_epoch=n_steps,\n    validation_data=valid_dataset,\n    epochs=EPOCHS\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"markdown","source":"n_steps = x_valid.shape[0] // BATCH_SIZE\ntrain_history_2 = model.fit(\n    valid_dataset.repeat(),\n    steps_per_epoch=n_steps,\n    epochs=EPOCHS*2\n)","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}